---
phase: 20-polish
plan: 01
type: execute
---

<objective>
Final UX polish for the v1.1 AI Diagram Experience milestone.

Purpose: Address the highest-impact UX gaps identified across the milestone - loading states, helpful tooltips, and scroll smoothness.
Output: Polished chat experience with clear feedback at every stage.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-phase.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

**v1.1 milestone context:**
This is the final phase of the v1.1 AI Diagram Experience milestone. Phases 13-19 built:
- Mermaid skill injection (Phase 13)
- Markdown rendering with syntax highlighting (Phase 14)
- Diagram block parsing (Phase 15)
- Diagram rendering in chat with view toggle (Phase 16)
- Template library (Phase 17)
- Diagram type auto-detection (Phase 18)
- Render fallback to ASCII (Phase 19)

**Key files:**
@src/components/chat/ChatPanel.vue - Main chat component
@src/components/chat/ChatMessage.vue - Individual message display
@src/components/chat/ContextIndicator.vue - Context file display

**Polish opportunities identified:**
1. No "Connecting..." state before first token arrives - users wonder if message sent
2. Token stats (tok/s) lack context - users don't understand the metrics
3. Context truncation warning has no explanation
4. Chat scrolls constantly during streaming - janky on slower devices
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add "Connecting..." state before streaming begins</name>
  <files>src/components/chat/ChatPanel.vue</files>
  <action>
Add a visual "Connecting..." state between when user sends message and when first token arrives.

1. Add a ref `isConnecting` that becomes true when message is sent
2. Set `isConnecting = false` when first streaming chunk arrives
3. Show "Connecting to AI..." in the typing indicator area when `isConnecting` is true
4. This addresses the UX gap where users don't know if their message was sent on slow connections

Implementation:
- In handleSendMessage(): Set isConnecting = true before starting stream
- In the onChunk callback: Set isConnecting = false on first chunk
- In template: Show connecting state in the typing indicator section
  </action>
  <verify>
1. Send a message
2. Confirm "Connecting..." appears immediately
3. Confirm it transitions to typing indicator when response starts
  </verify>
  <done>
- "Connecting..." state visible between send and first token
- Smooth transition to typing indicator
  </done>
</task>

<task type="auto">
  <name>Task 2: Add tooltips to token stats and truncation warnings</name>
  <files>src/components/chat/ChatMessage.vue, src/components/chat/ContextIndicator.vue</files>
  <action>
Add helpful tooltips that explain metrics and warnings to users.

In ChatMessage.vue:
1. Add title attribute to token stats display explaining "tok/s":
   - "Tokens per second - measures AI response speed"
2. Add title to token count explaining it's estimated:
   - "Estimated token count (actual may vary by model)"

In ContextIndicator.vue:
1. Add title attribute to "(truncated)" indicator:
   - "File content was shortened to fit within AI context limits"
2. Style truncation indicator with a subtle warning color

Keep tooltips concise and helpful - no jargon.
  </action>
  <verify>
1. Hover over token stats - tooltip appears
2. Hover over truncated indicator - tooltip explains why
  </verify>
  <done>
- Token stats have explanatory tooltips
- Truncation warning has helpful tooltip
  </done>
</task>

<task type="auto">
  <name>Task 3: Debounce chat scroll during streaming</name>
  <files>src/components/chat/ChatPanel.vue</files>
  <action>
Improve scroll performance during streaming by debouncing scrollToBottom calls.

1. Import useDebounceFn from @vueuse/core (already in project)
2. Create debounced version of scrollToBottom with ~100ms delay
3. Use debounced scroll during streaming chunks
4. Keep immediate scroll for user-initiated actions (send message, clear)

This prevents constant scroll calls during fast streaming which can cause jank.
  </action>
  <verify>
1. Start a long AI response
2. Observe smooth scrolling (no jitter)
3. Manual scroll should still work during streaming
  </verify>
  <done>
- Smooth scrolling during streaming
- No performance jank on long responses
  </done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] `npm run type-check` passes
- [ ] `npm run build` succeeds
- [ ] "Connecting..." state appears on message send
- [ ] Tooltips visible on hover for stats and truncation
- [ ] Smooth scroll during streaming
</verification>

<success_criteria>
- Clear feedback at every stage of AI interaction
- Users understand metrics via tooltips
- Smooth scroll performance during streaming
- Type check and build pass
- v1.1 milestone ready for completion
</success_criteria>

<output>
After completion, create `.planning/phases/20-polish/20-01-SUMMARY.md`
</output>
